https://www.slideshare.net/Simplilearn/introduction-to-devops-devops-tutorial-for-beginners-devops-training-for-beginners-simplilearn
 KNN
 it is based on supervised learning technique
  it can be used in both regression as well as classification but mostly used 
in classification problem.
   it is a non parametric algorithm
   it is also called as lazy learner

   The K-NN working can be explained on the basis of the below algorithm:

Step-1: Select the number K of the neighbors
Step-2: Calculate the Euclidean distance of K number of neighbors
Step-3: Take the K nearest neighbors as per the calculated Euclidean distance.
Step-4: Among these k neighbors, count the number of the data points in each category.
Step-5: Assign the new data points to that category for which the number of the neighbor is maximum.
Step-6: Our model is ready.




      Suppose we have a new data point and we need to put it in the required category. Consider the below image:

    K-Nearest Neighbor(KNN) Algorithm for Machine Learning
    Firstly, we will choose the number of neighbors, so we will choose the k=5.
    Next, we will calculate the Euclidean distance between the data points. The Euclidean distance is the distance between two points, which we have already studied in geometry. It can be calculated as:
    K-Nearest Neighbor(KNN) Algorithm for Machine Learning
    By calculating the Euclidean distance we got the nearest neighbors, as three nearest neighbors in category A and two nearest neighbors in category B.
 Consider the below image:
    K-Nearest Neighbor(KNN) Algorithm for Machine Learning
    As we can see the 3 nearest neighbors are from category A, hence this new data point must belong to category A.


    supervised ML
     
      Supervised learning is the types of machine learning in which machines are trained using well "labelled" training data, and on basis of that data, 
machines predict the output. The labelled data means some input data is already tagged with the correct output.
     types of supervised ML
  1. Regression
      Regression analysis is a statistical method to model the relationship between a dependent (target) and independent (predictor) variables with 
one or more independent variables. More specifically, Regression analysis helps us to understand how the value of the dependent 
variable is changing corresponding to an independent variable when other independent variables are held fixed.
 It predicts continuous/real values such as temperature, age, salary, price, etc.
            Regression Alogrithm
    linear regression/Least square method/least square error:
  here u have to find the dependent variable based on the behaviour of independent variables.
 -> Normal distribution/bellcurve/gaussion
 ->Assumption of linear regression
  -> Cost function optimization
 2.Classification
     The Classification algorithm is a Supervised Learning technique that is used to identify the category of new observations 
on the basis of training data. In Classification, a program learns from the given dataset or observations and then classifies
 new observation into a number of classes or groups. Such as, Yes or No, 0 or 1, Spam or Not Spam, cat or dog, etc.
 Classes can be called as targets/labels or categories.



  BIAS THEOREM
   Bayes' theorem is also known as Bayes' Rule or Bayes' law, which is used to determine the probability of a hypothesis with prior knowledge.
 It depends on the conditional probability.
   P(A/B)= P(B/A)*P(A)/P(B)
 
  NAIVE BAYES
   Na√Øve Bayes algorithm is a supervised learning algorithm, which is based on Bayes theorem and used for solving classification problems.
   

   ARGMAX 
 It gives u which cls has max probability 
p=argmax(pXs/y)*p(y)
 here record should be independent
  

  DECISION TREE
  
Decision Tree is a Supervised learning technique that can be used for both classification and Regression problems, 
but mostly it is preferred for solving Classification problems. It is a tree-structured classifier,
 where internal nodes represent the features of a dataset, branches represent the decision rules and each leaf node represents the outcome.
  

    REGULARIZATIONS
 Regularization is one of the most important concepts of machine learning. It is a technique to prevent the model from overfitting by adding extra information to it.

Sometimes the machine learning model performs well with the training data but does not perform well with the test data. It means the model is
 not able to predict the output when deals with unseen data by introducing noise in the output, and hence the model is called overfitted.
 This problem can be deal with the help of a regularization technique.

This technique can be used in such a way that it will allow to maintain all variables or features in the model by reducing the magnitude of the variables. 
Hence, it maintains accuracy as well as a generalization of the model.
  



 THERE R 3 TECHNIQUES
 L1 LASSO
 L2 RIDGE
 DROPOUT
 

 overfitting
Overfitting occurs when our machine learning model tries to cover all the data points or more than the required data points present in the given dataset.
 Because of this, the model starts caching noise and inaccurate values present in the dataset, and all these factors reduce the efficiency and accuracy of the model.
 The overfitted model has low bias and high variance.
The chances of occurrence of overfitting increase as much we provide training to our model. 
It means the more we train our model, the more chances of occurring the overfitted model.
    

   underfitting
Underfitting occurs when our machine learning model is not able to capture the underlying trend of the data. 
To avoid the overfitting in the model, the fed of training data can be stopped at an early stage, due to which the model may not learn enough from the training data.
 As a result, it may fail to find the best fit of the dominant trend in the data.

In the case of underfitting, the model is not able to learn enough from the training data, and hence it reduces the accuracy and produces unreliable predictions.
An underfitted model has high bias and low variance.



poloclub.github.io/cnn-explainer/
                